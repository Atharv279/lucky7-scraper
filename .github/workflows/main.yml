name: lucky7-scrape

on:
  schedule:
    - cron: "*/5 * * * *"   # every 5 minutes
  workflow_dispatch: {}

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 55
    concurrency:
      group: lucky7-scrape-${{ github.ref }}
      cancel-in-progress: false
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1

      - name: Xvfb
        run: sudo apt-get update && sudo apt-get install -y xvfb

      - name: Pip install
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager beautifulsoup4

      - name: Run scraper
        env:
          NOH_USER: ${{ secrets.NOH_USER }}
          NOH_PASS: ${{ secrets.NOH_PASS }}
          RUN_SECONDS: "3000"      # ~50 minutes/run
          MAX_ROUNDS: "0"
          CSV_PATH: "lucky7_data.csv"
          PYTHONUNBUFFERED: "1"
          DEBUG_DUMP: "1"
        run: |
          xvfb-run -a -s "-screen 0 1600x900x24" python -u scraper.py

      - name: Show CSV tail
        if: always()
        run: |
          ls -lah
          if [ -f lucky7_data.csv ]; then
            echo "---- CSV tail ----"
            tail -n 50 lucky7_data.csv
          else
            echo "CSV not created."
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-${{ github.run_id }}
          path: |
            debug/**
            lucky7_data.csv
          if-no-files-found: warn

      - name: Commit CSV
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "data: update CSV [skip ci]"
          file_pattern: |
            lucky7_data.csv
            data/*.csv
